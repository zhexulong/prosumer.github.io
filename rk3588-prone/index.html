<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="generator" content="Gatsby 5.13.5"/><meta name="description" content="对UNet模型进行剪枝,提升推理速度" data-gatsby-head="true"/><meta property="og:title" content="从UNet模型剪枝到rk3588板端推理部署" data-gatsby-head="true"/><meta property="og:description" content="对UNet模型进行剪枝,提升推理速度" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta name="twitter:card" content="summary" data-gatsby-head="true"/><meta name="twitter:creator" content="kylemathews" data-gatsby-head="true"/><meta name="twitter:title" content="从UNet模型剪枝到rk3588板端推理部署" data-gatsby-head="true"/><meta name="twitter:description" content="对UNet模型进行剪枝,提升推理速度" data-gatsby-head="true"/><style data-href="/styles.cf3dca79c4c295eec224.css" data-identity="gatsby-global-css">@font-face{font-display:swap;font-family:Montserrat Variable;font-style:normal;font-weight:100 900;src:url(/static/montserrat-cyrillic-ext-wght-normal-e84e812b71d18e04e6928fb272665c53.woff2) format("woff2-variations");unicode-range:u+0460-052f,u+1c80-1c88,u+20b4,u+2de0-2dff,u+a640-a69f,u+fe2e-fe2f}@font-face{font-display:swap;font-family:Montserrat Variable;font-style:normal;font-weight:100 900;src:url(/static/montserrat-cyrillic-wght-normal-eb1783eb42487132539645641f761eb2.woff2) format("woff2-variations");unicode-range:u+0301,u+0400-045f,u+0490-0491,u+04b0-04b1,u+2116}@font-face{font-display:swap;font-family:Montserrat Variable;font-style:normal;font-weight:100 900;src:url(data:font/woff2;base64,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) format("woff2-variations");unicode-range:u+0102-0103,u+0110-0111,u+0128-0129,u+0168-0169,u+01a0-01a1,u+01af-01b0,u+0300-0301,u+0303-0304,u+0308-0309,u+0323,u+0329,u+1ea0-1ef9,u+20ab}@font-face{font-display:swap;font-family:Montserrat Variable;font-style:normal;font-weight:100 900;src:url(/static/montserrat-latin-ext-wght-normal-82d636d9375dd92118fd22c818a99c24.woff2) format("woff2-variations");unicode-range:u+0100-02af,u+0304,u+0308,u+0329,u+1e00-1e9f,u+1ef2-1eff,u+2020,u+20a0-20ab,u+20ad-20cf,u+2113,u+2c60-2c7f,u+a720-a7ff}@font-face{font-display:swap;font-family:Montserrat Variable;font-style:normal;font-weight:100 900;src:url(/static/montserrat-latin-wght-normal-5028c63f6a70ab0cf7cba9015ae04154.woff2) format("woff2-variations");unicode-range:u+00??,u+0131,u+0152-0153,u+02bb-02bc,u+02c6,u+02da,u+02dc,u+0304,u+0308,u+0329,u+2000-206f,u+2074,u+20ac,u+2122,u+2191,u+2193,u+2212,u+2215,u+feff,u+fffd}@font-face{font-display:swap;font-family:Merriweather;font-style:normal;font-weight:400;src:url(/static/merriweather-cyrillic-ext-400-normal-2a880e22b1b888ab54652a36d43b7f16.woff2) format("woff2"),url(/static/merriweather-cyrillic-ext-400-normal-7d8546944154663cc54693d15bb31721.woff) format("woff");unicode-range:u+0460-052f,u+1c80-1c88,u+20b4,u+2de0-2dff,u+a640-a69f,u+fe2e-fe2f}@font-face{font-display:swap;font-family:Merriweather;font-style:normal;font-weight:400;src:url(/static/merriweather-cyrillic-400-normal-fde0b55efc50742fb57fbebbb11c572f.woff2) format("woff2"),url(/static/merriweather-cyrillic-400-normal-2e7c71643f6e0e4c1e73f28a7a1798e6.woff) format("woff");unicode-range:u+0301,u+0400-045f,u+0490-0491,u+04b0-04b1,u+2116}@font-face{font-display:swap;font-family:Merriweather;font-style:normal;font-weight:400;src:url(data:font/woff2;base64,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) format("woff2"),url(data:font/woff;base64,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) format("woff");unicode-range:u+0102-0103,u+0110-0111,u+0128-0129,u+0168-0169,u+01a0-01a1,u+01af-01b0,u+0300-0301,u+0303-0304,u+0308-0309,u+0323,u+0329,u+1ea0-1ef9,u+20ab}@font-face{font-display:swap;font-family:Merriweather;font-style:normal;font-weight:400;src:url(/static/merriweather-latin-ext-400-normal-4657f5ab02d5923d223f96a9155a9bdc.woff2) format("woff2"),url(/static/merriweather-latin-ext-400-normal-7b1ee735b2541bc831bd57bacecc9d41.woff) format("woff");unicode-range:u+0100-02af,u+0304,u+0308,u+0329,u+1e00-1e9f,u+1ef2-1eff,u+2020,u+20a0-20ab,u+20ad-20cf,u+2113,u+2c60-2c7f,u+a720-a7ff}@font-face{font-display:swap;font-family:Merriweather;font-style:normal;font-weight:400;src:url(/static/merriweather-latin-400-normal-e009f21405b4d7e893674b69deb4cf4a.woff2) format("woff2"),url(/static/merriweather-latin-400-normal-2c455928024d0ee049d896a25f9e30e1.woff) format("woff");unicode-range:u+00??,u+0131,u+0152-0153,u+02bb-02bc,u+02c6,u+02da,u+02dc,u+0304,u+0308,u+0329,u+2000-206f,u+2074,u+20ac,u+2122,u+2191,u+2193,u+2212,u+2215,u+feff,u+fffd}
/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{-webkit-text-size-adjust:100%;line-height:1.15}body{margin:0}main{display:block}h1{font-size:2em;margin:.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}[hidden]{display:none}:root{--maxWidth-none:"none";--maxWidth-xs:20rem;--maxWidth-sm:24rem;--maxWidth-md:28rem;--maxWidth-lg:32rem;--maxWidth-xl:36rem;--maxWidth-2xl:42rem;--maxWidth-3xl:48rem;--maxWidth-4xl:56rem;--maxWidth-full:"100%";--maxWidth-wrapper:var(--maxWidth-2xl);--spacing-px:"1px";--spacing-0:0;--spacing-1:0.25rem;--spacing-2:0.5rem;--spacing-3:0.75rem;--spacing-4:1rem;--spacing-5:1.25rem;--spacing-6:1.5rem;--spacing-8:2rem;--spacing-10:2.5rem;--spacing-12:3rem;--spacing-16:4rem;--spacing-20:5rem;--spacing-24:6rem;--spacing-32:8rem;--fontFamily-sans:"MontserratVariable",system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";--fontFamily-serif:"Merriweather","Georgia",Cambria,"Times New Roman",Times,serif;--font-body:var(--fontFamily-serif);--font-heading:var(--fontFamily-sans);--fontWeight-normal:400;--fontWeight-bold:700;--fontWeight-black:900;--fontSize-root:16px;--lineHeight-none:1;--lineHeight-tight:1.1;--lineHeight-normal:1.5;--lineHeight-relaxed:1.625;--fontSize-0:0.833rem;--fontSize-1:1rem;--fontSize-2:1.2rem;--fontSize-3:1.44rem;--fontSize-4:1.728rem;--fontSize-5:2.074rem;--fontSize-6:2.488rem;--fontSize-7:2.986rem;--color-primary:#005b99;--color-text:#2e353f;--color-text-light:#4f5969;--color-heading:#1a202c;--color-heading-black:#000;--color-accent:#d1dce5}*,:after,:before{box-sizing:border-box}html{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;font-size:var(--fontSize-root);line-height:var(--lineHeight-normal)}body{color:var(--color-text);font-family:var(--font-body);font-size:var(--fontSize-1)}footer{padding:var(--spacing-6) var(--spacing-0)}hr{background:var(--color-accent);border:0;height:1px}h1,h2,h3,h4,h5,h6{font-family:var(--font-heading);letter-spacing:-.025em;line-height:var(--lineHeight-tight);margin-bottom:var(--spacing-6);margin-top:var(--spacing-12)}h2,h3,h4,h5,h6{color:var(--color-heading);font-weight:var(--fontWeight-bold)}h1{color:var(--color-heading-black);font-size:var(--fontSize-6);font-weight:var(--fontWeight-black)}h2{font-size:var(--fontSize-5)}h3{font-size:var(--fontSize-4)}h4{font-size:var(--fontSize-3)}h5{font-size:var(--fontSize-2)}h6{font-size:var(--fontSize-1)}h1>a,h2>a,h3>a,h4>a,h5>a,h6>a{color:inherit;text-decoration:none}p{--baseline-multiplier:0.179;--x-height-multiplier:0.35;line-height:var(--lineHeight-relaxed);margin:var(--spacing-0) var(--spacing-0) var(--spacing-8) var(--spacing-0)}ol,p,ul{padding:var(--spacing-0)}ol,ul{list-style-image:none;list-style-position:outside;margin-bottom:var(--spacing-8);margin-left:var(--spacing-0);margin-right:var(--spacing-0)}ol li,ul li{padding-left:var(--spacing-0)}li>p,ol li,ul li{margin-bottom:calc(var(--spacing-8)/2)}li :last-child{margin-bottom:var(--spacing-0)}li>ul{margin-left:var(--spacing-8);margin-top:calc(var(--spacing-8)/2)}blockquote{border-left:var(--spacing-1) solid var(--color-primary);color:var(--color-text-light);font-size:var(--fontSize-2);font-style:italic;margin-bottom:var(--spacing-8);margin-left:calc(var(--spacing-6)*-1);margin-right:var(--spacing-8);padding:var(--spacing-0) var(--spacing-0) var(--spacing-0) var(--spacing-6)}blockquote>:last-child{margin-bottom:var(--spacing-0)}blockquote>ol,blockquote>ul{list-style-position:inside}table{border-collapse:collapse;border-spacing:.25rem;margin-bottom:var(--spacing-8);width:100%}table thead tr th{border-bottom:1px solid var(--color-accent)}a{color:var(--color-primary)}a:focus,a:hover{text-decoration:none}.global-wrapper{margin:var(--spacing-0) auto;max-width:var(--maxWidth-wrapper);padding:var(--spacing-10) var(--spacing-5)}.global-wrapper[data-is-root-path=true] .bio{margin-bottom:var(--spacing-20)}.global-header{margin-bottom:var(--spacing-12)}.main-heading{font-size:var(--fontSize-7);margin:0}.post-list-item{margin-bottom:var(--spacing-8);margin-top:var(--spacing-8)}.post-list-item p{margin-bottom:var(--spacing-0)}.post-list-item h2{color:var(--color-primary);font-size:var(--fontSize-4);margin-bottom:var(--spacing-2);margin-top:var(--spacing-0)}.post-list-item header{margin-bottom:var(--spacing-4)}.header-link-home{font-family:var(--font-heading);font-size:var(--fontSize-2);font-weight:var(--fontWeight-bold);text-decoration:none}.bio{display:flex;margin-bottom:var(--spacing-16)}.bio p,.bio-avatar{margin-bottom:var(--spacing-0)}.bio-avatar{border-radius:100%;margin-right:var(--spacing-4);min-width:50px}.blog-post header h1{margin:var(--spacing-0) var(--spacing-0) var(--spacing-4) var(--spacing-0)}.blog-post header p{font-family:var(--font-heading);font-size:var(--fontSize-2)}.blog-post-nav ul{margin:var(--spacing-0)}.gatsby-highlight{margin-bottom:var(--spacing-8)}@media (max-width:42rem){blockquote{margin-left:var(--spacing-0);padding:var(--spacing-0) var(--spacing-0) var(--spacing-0) var(--spacing-4)}ol,ul{list-style-position:inside}}code[class*=language-],pre[class*=language-]{word-wrap:normal;background:none;color:#000;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;-webkit-hyphens:none;hyphens:none;line-height:1.5;tab-size:4;text-align:left;text-shadow:0 1px #fff;white-space:pre;word-break:normal;word-spacing:normal}code[class*=language-] ::selection,code[class*=language-]::selection,pre[class*=language-] ::selection,pre[class*=language-]::selection{background:#b3d4fc;text-shadow:none}@media print{code[class*=language-],pre[class*=language-]{text-shadow:none}}pre[class*=language-]{margin:.5em 0;overflow:auto;padding:1em}:not(pre)>code[class*=language-],pre[class*=language-]{background:#f5f2f0}:not(pre)>code[class*=language-]{border-radius:.3em;padding:.1em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#708090}.token.punctuation{color:#999}.token.namespace{opacity:.7}.token.boolean,.token.constant,.token.deleted,.token.number,.token.property,.token.symbol,.token.tag{color:#905}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#690}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url{background:hsla(0,0%,100%,.5);color:#9a6e3a}.token.atrule,.token.attr-value,.token.keyword{color:#07a}.token.class-name,.token.function{color:#dd4a68}.token.important,.token.regex,.token.variable{color:#e90}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}</style><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper picture.object-fit-polyfill{position:static!important}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){const t=e.target;if(void 0===t.dataset.mainImage)return;if(void 0===t.dataset.gatsbyImageSsr)return;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script><link rel="alternate" type="application/rss+xml" title="Gatsby Starter Blog RSS Feed" href="/rss.xml"/><link rel="icon" href="/favicon-32x32.png?v=4a9773549091c227cd2eb82ccd9c5e3a" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=4a9773549091c227cd2eb82ccd9c5e3a"/><title data-gatsby-head="true">从UNet模型剪枝到rk3588板端推理部署 | Gatsby Starter Blog</title></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="global-wrapper" data-is-root-path="false"><header class="global-header"><a class="header-link-home" href="/">Gatsby Starter Blog</a></header><main><article class="blog-post" itemscope="" itemType="http://schema.org/Article"><header><h1 itemProp="headline">从UNet模型剪枝到rk3588板端推理部署</h1><p>June 10, 2024</p></header><section itemProp="articleBody"><h2>模型剪枝</h2>
<h3>剪枝所需工具型代码</h3>
<p>下面是相应python代码</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn


<span class="token keyword">class</span> <span class="token class-name">Pruner</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> net<span class="token punctuation">,</span> flops_reg<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>net <span class="token operator">=</span> net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># Initialize stuff</span>
        self<span class="token punctuation">.</span>flops_reg <span class="token operator">=</span> flops_reg
        self<span class="token punctuation">.</span>clear_rank<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>clear_modules<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>clear_cache<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># Set hooks</span>
        self<span class="token punctuation">.</span>hook_handler <span class="token operator">=</span> self<span class="token punctuation">.</span>_register_hooks<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">clear_rank</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>ranks <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>  <span class="token comment"># accumulates Taylor ranks for modules</span>
        self<span class="token punctuation">.</span>flops <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">clear_modules</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>convs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>BNs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">clear_cache</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>activation_maps <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>gradients <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">forward_hook_fn</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> module<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> output<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">""" Stores the forward pass outputs (activation maps)"""</span>
        self<span class="token punctuation">.</span>activation_maps<span class="token punctuation">.</span>append<span class="token punctuation">(</span>output<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">backward_hook_fn</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> module<span class="token punctuation">,</span> grad_in<span class="token punctuation">,</span> grad_out<span class="token punctuation">)</span><span class="token punctuation">:</span>
         <span class="token triple-quoted-string string">"""Stores the gradients wrt outputs during backprop"""</span>
         self<span class="token punctuation">.</span>gradients<span class="token punctuation">.</span>append<span class="token punctuation">(</span>grad_out<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_register_hooks</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        handler_registry <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> name<span class="token punctuation">,</span> module <span class="token keyword">in</span> self<span class="token punctuation">.</span>net<span class="token punctuation">.</span>named_modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> name <span class="token operator">!=</span> <span class="token string">"outc"</span><span class="token punctuation">:</span>  <span class="token comment"># don't hook final conv module</span>
                    handle_back <span class="token operator">=</span> module<span class="token punctuation">.</span>register_full_backward_hook<span class="token punctuation">(</span>self<span class="token punctuation">.</span>backward_hook_fn<span class="token punctuation">)</span>
                    handle_forw <span class="token operator">=</span> module<span class="token punctuation">.</span>register_forward_hook<span class="token punctuation">(</span>self<span class="token punctuation">.</span>forward_hook_fn<span class="token punctuation">)</span>
                    handler_registry<span class="token punctuation">.</span>append<span class="token punctuation">(</span>handle_back<span class="token punctuation">)</span>
                    handler_registry<span class="token punctuation">.</span>append<span class="token punctuation">(</span>handle_forw<span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>convs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>module<span class="token punctuation">)</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>BNs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>module<span class="token punctuation">)</span>  <span class="token comment"># save corresponding BN layer</span>
        <span class="token keyword">return</span> handler_registry

    <span class="token keyword">def</span> <span class="token function">compute_rank</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># Compute ranks after each minibatch</span>
        self<span class="token punctuation">.</span>gradients<span class="token punctuation">.</span>reverse<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> layer<span class="token punctuation">,</span> act <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>activation_maps<span class="token punctuation">)</span><span class="token punctuation">:</span>
            taylor <span class="token operator">=</span> <span class="token punctuation">(</span>act<span class="token operator">*</span>self<span class="token punctuation">.</span>gradients<span class="token punctuation">[</span>layer<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># C</span>

            <span class="token keyword">if</span> layer <span class="token keyword">not</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>ranks<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># no such entry</span>
                self<span class="token punctuation">.</span>ranks<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">{</span>layer<span class="token punctuation">:</span> taylor<span class="token punctuation">}</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>ranks<span class="token punctuation">[</span>layer<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">.9</span><span class="token operator">*</span>self<span class="token punctuation">.</span>ranks<span class="token punctuation">[</span>layer<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">.1</span><span class="token operator">*</span>taylor  <span class="token comment"># C</span>
        self<span class="token punctuation">.</span>clear_cache<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_rank_channels</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> prune_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        total_rank <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># flattened ranks of each channel, all layers</span>
        channel_layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># layer num for each channel</span>
        layer_channels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># channel num wrt layer for each channel</span>
        self<span class="token punctuation">.</span>flops<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>x <span class="token operator">/</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>flops<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> self<span class="token punctuation">.</span>flops<span class="token punctuation">]</span>  <span class="token comment"># Normalize FLOPs</span>
        <span class="token comment"># print(self.flops, self.ranks.items())</span>
        <span class="token keyword">for</span> layer<span class="token punctuation">,</span> ranks <span class="token keyword">in</span> self<span class="token punctuation">.</span>ranks<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># Average across minibatches</span>
            taylor <span class="token operator">=</span> ranks  <span class="token comment"># C</span>
            <span class="token comment"># Layer-wise L2 normalization</span>
            taylor <span class="token operator">=</span> taylor <span class="token operator">/</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>taylor<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># C</span>
            total_rank<span class="token punctuation">.</span>append<span class="token punctuation">(</span>taylor <span class="token operator">+</span> self<span class="token punctuation">.</span>flops<span class="token punctuation">[</span>layer<span class="token punctuation">]</span><span class="token operator">*</span>self<span class="token punctuation">.</span>flops_reg<span class="token punctuation">)</span>
            channel_layers<span class="token punctuation">.</span>extend<span class="token punctuation">(</span><span class="token punctuation">[</span>layer<span class="token punctuation">]</span><span class="token operator">*</span>ranks<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            layer_channels<span class="token punctuation">.</span>extend<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>ranks<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        channel_layers <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>channel_layers<span class="token punctuation">)</span>
        layer_channels <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>layer_channels<span class="token punctuation">)</span>
        total_rank <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>total_rank<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

        <span class="token comment"># Rank</span>
        sorted_rank<span class="token punctuation">,</span> sorted_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>total_rank<span class="token punctuation">,</span> prune_channels<span class="token punctuation">,</span> largest<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        sorted_channel_layers <span class="token operator">=</span> channel_layers<span class="token punctuation">[</span>sorted_indices<span class="token punctuation">]</span>
        sorted_layer_channels <span class="token operator">=</span> layer_channels<span class="token punctuation">[</span>sorted_indices<span class="token punctuation">]</span>
        <span class="token keyword">return</span> sorted_channel_layers<span class="token punctuation">,</span> sorted_layer_channels

    <span class="token keyword">def</span> <span class="token function">pruning</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> prune_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>

        sorted_channel_layers<span class="token punctuation">,</span> sorted_layer_channels <span class="token operator">=</span> self<span class="token punctuation">.</span>_rank_channels<span class="token punctuation">(</span>prune_channels<span class="token punctuation">)</span>
        inchans<span class="token punctuation">,</span> outchans <span class="token operator">=</span> self<span class="token punctuation">.</span>create_indices<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>sorted_channel_layers<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            cl <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>sorted_channel_layers<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
            lc <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>sorted_layer_channels<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>

            <span class="token comment"># These tensors are concat at a later conv2d</span>
            <span class="token comment"># res_prev = {1:16, 3:14, 5:12, 7:10}</span>
            res <span class="token operator">=</span> <span class="token boolean">True</span> <span class="token keyword">if</span> cl <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span> <span class="token keyword">else</span> <span class="token boolean">False</span>

            <span class="token comment"># These tensors are concat with an earlier tensor at bottom.</span>
            offset <span class="token operator">=</span> <span class="token boolean">True</span> <span class="token keyword">if</span> cl <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">]</span> <span class="token keyword">else</span> <span class="token boolean">False</span>

            <span class="token comment"># Remove indices of pruned parameters/channels</span>
            <span class="token keyword">if</span> offset<span class="token punctuation">:</span>
                mapping <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token number">9</span><span class="token punctuation">:</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">}</span>
                top <span class="token operator">=</span> self<span class="token punctuation">.</span>convs<span class="token punctuation">[</span>mapping<span class="token punctuation">[</span>cl<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
                <span class="token keyword">try</span><span class="token punctuation">:</span>
                    inchans<span class="token punctuation">[</span>cl <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>remove<span class="token punctuation">(</span>top <span class="token operator">+</span> lc<span class="token punctuation">)</span>  <span class="token comment"># it is searching for a -ve number to remove, but there are none</span>
                    <span class="token comment"># However, the output channel of the previous layer (d4) is reduced</span>
                    <span class="token comment"># So up1's input channel is larger than expected due to failed removal</span>
                <span class="token keyword">except</span> ValueError<span class="token punctuation">:</span>
                    <span class="token keyword">pass</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token keyword">try</span><span class="token punctuation">:</span>
                    inchans<span class="token punctuation">[</span>cl <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>remove<span class="token punctuation">(</span>lc<span class="token punctuation">)</span>
                <span class="token keyword">except</span> ValueError<span class="token punctuation">:</span>
                    <span class="token keyword">pass</span>
            <span class="token keyword">if</span> res<span class="token punctuation">:</span>
                <span class="token keyword">try</span><span class="token punctuation">:</span>
                    inchans<span class="token punctuation">[</span><span class="token operator">-</span><span class="token punctuation">(</span>cl <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>remove<span class="token punctuation">(</span>lc<span class="token punctuation">)</span>
                <span class="token keyword">except</span> ValueError<span class="token punctuation">:</span>
                    <span class="token keyword">pass</span>
            <span class="token keyword">try</span><span class="token punctuation">:</span>
                outchans<span class="token punctuation">[</span>cl<span class="token punctuation">]</span><span class="token punctuation">.</span>remove<span class="token punctuation">(</span>lc<span class="token punctuation">)</span>
            <span class="token keyword">except</span> ValueError<span class="token punctuation">:</span>
                <span class="token keyword">pass</span>

        <span class="token comment"># Use indexing to get rid of parameters</span>
        <span class="token comment"># print(self.convs, inchans, outchans)</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> c <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>convs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>convs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data <span class="token operator">=</span> c<span class="token punctuation">.</span>weight<span class="token punctuation">[</span>outchans<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> inchans<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
            self<span class="token punctuation">.</span>convs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>bias <span class="token operator">=</span> <span class="token boolean">None</span>

        <span class="token keyword">for</span> i<span class="token punctuation">,</span> bn <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>BNs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>BNs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>running_mean<span class="token punctuation">.</span>data <span class="token operator">=</span> bn<span class="token punctuation">.</span>running_mean<span class="token punctuation">[</span>outchans<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span>
            self<span class="token punctuation">.</span>BNs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>running_var<span class="token punctuation">.</span>data <span class="token operator">=</span> bn<span class="token punctuation">.</span>running_var<span class="token punctuation">[</span>outchans<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span>
            self<span class="token punctuation">.</span>BNs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data <span class="token operator">=</span> bn<span class="token punctuation">.</span>weight<span class="token punctuation">[</span>outchans<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span>
            self<span class="token punctuation">.</span>BNs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>bias <span class="token operator">=</span> <span class="token boolean">None</span>

    <span class="token keyword">def</span> <span class="token function">create_indices</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        chans <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>c<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>c<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> self<span class="token punctuation">.</span>convs<span class="token punctuation">]</span>
        inchans<span class="token punctuation">,</span> outchans <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token operator">*</span>chans<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> inchans<span class="token punctuation">,</span> outchans

    <span class="token keyword">def</span> <span class="token function">channel_save</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> path<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""save the 22 distinct number of channels"""</span>
        chans <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> c <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>convs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">></span> <span class="token number">8</span> <span class="token keyword">and</span> <span class="token punctuation">(</span>i<span class="token operator">-</span><span class="token number">9</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword">or</span> i <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                chans<span class="token punctuation">.</span>append<span class="token punctuation">(</span>c<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            chans<span class="token punctuation">.</span>append<span class="token punctuation">(</span>c<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            <span class="token keyword">for</span> item <span class="token keyword">in</span> chans<span class="token punctuation">:</span>
                f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"%s\n"</span> <span class="token operator">%</span> item<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">calc_flops</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Calculate flops per tensor channel. Only consider flops
        of conv2d that produces said feature map
        """</span>
        <span class="token comment"># conv2d: slides*(kernel mult + kernel sum + bias)</span>
        <span class="token comment"># kernel_sum = kernel_mult - 1</span>
        <span class="token comment"># conv2d: slides*(2*kernel mult)</span>

        <span class="token comment"># batchnorm2d: 4*slides</span>

        <span class="token comment"># Remove unnecessary constants from calculation</span>

        <span class="token keyword">for</span> i<span class="token punctuation">,</span> c <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>convs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            H<span class="token punctuation">,</span> W <span class="token operator">=</span> self<span class="token punctuation">.</span>gradients<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
            O<span class="token punctuation">,</span> I<span class="token punctuation">,</span> KH<span class="token punctuation">,</span> KW <span class="token operator">=</span> c<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>shape
            self<span class="token punctuation">.</span>flops<span class="token punctuation">.</span>append<span class="token punctuation">(</span>H<span class="token operator">*</span>W<span class="token operator">*</span>KH<span class="token operator">*</span>KW<span class="token operator">*</span>I<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>flops

    <span class="token keyword">def</span> <span class="token function">close</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> handle <span class="token keyword">in</span> self<span class="token punctuation">.</span>hook_handler<span class="token punctuation">:</span>
            handle<span class="token punctuation">.</span>remove<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span></code></pre></div>
<h3>剪枝过程</h3>
<p>下面是相应python代码,只表示所需过程,仅供读者参考</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">	<span class="token keyword">from</span> prune_utils <span class="token keyword">import</span> Pruner
    net <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'./model.pth'</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token string">'cpu'</span><span class="token punctuation">)</span>
    pruner <span class="token operator">=</span> Pruner<span class="token punctuation">(</span>net<span class="token punctuation">,</span> <span class="token number">.001</span><span class="token punctuation">)</span>
    batch_size <span class="token operator">=</span> <span class="token number">32</span>
    <span class="token keyword">with</span> tqdm<span class="token punctuation">(</span>total<span class="token operator">=</span><span class="token number">10</span> <span class="token operator">*</span> batch_size<span class="token punctuation">)</span> <span class="token keyword">as</span> progress_bar<span class="token punctuation">:</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader_train<span class="token punctuation">)</span><span class="token punctuation">:</span>
            masks_pred <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>masks_pred<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            pruner<span class="token punctuation">.</span>compute_rank<span class="token punctuation">(</span><span class="token punctuation">)</span>
            progress_bar<span class="token punctuation">.</span>update<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>
            <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">10</span><span class="token punctuation">:</span>
                <span class="token keyword">break</span>

    pruner<span class="token punctuation">.</span>pruning<span class="token punctuation">(</span><span class="token number">300</span><span class="token punctuation">)</span>
    pruner<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">,</span> <span class="token string">"pruned_model.pth"</span><span class="token punctuation">)</span></code></pre></div>
<h3>微调(fine-tune)部分</h3>
<p>下面是相应python代码,solver中实现了模型训练所需逻辑,暂无法提供源码</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">    net <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"pruned_model.pth"</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token string">'cuda:0'</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> parameters <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token string">':'</span><span class="token punctuation">,</span> parameters<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>
    lr_scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>ExponentialLR<span class="token punctuation">(</span>optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.95</span><span class="token punctuation">)</span>

    solver <span class="token operator">=</span> lab<span class="token punctuation">.</span>Solver<span class="token punctuation">(</span>
        model<span class="token operator">=</span>net<span class="token punctuation">,</span>
        optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span>
        criterion<span class="token operator">=</span>MyBinaryCrossEntropy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        lr_scheduler<span class="token operator">=</span>lr_scheduler
    <span class="token punctuation">)</span>
    solver<span class="token punctuation">.</span>train<span class="token punctuation">(</span>
        epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
        data_loader<span class="token operator">=</span>dataloader_train<span class="token punctuation">,</span>
        val_loader<span class="token operator">=</span>dataloader_val<span class="token punctuation">,</span>
        save_path<span class="token operator">=</span><span class="token string">'./model_finetune.pth'</span><span class="token punctuation">,</span>
        img_name<span class="token operator">=</span><span class="token string">'model_finetune'</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span></code></pre></div>
<h3>剪枝效果</h3>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">from</span> thop <span class="token keyword">import</span> profile
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
lr_scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>ExponentialLR<span class="token punctuation">(</span>optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.99</span><span class="token punctuation">)</span>
net <span class="token operator">=</span>  torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"./model_finetune.pth"</span><span class="token punctuation">)</span>
net <span class="token operator">=</span> net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
dataiter <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>dataloader_test<span class="token punctuation">)</span>
images<span class="token punctuation">,</span> labels <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span>dataiter<span class="token punctuation">)</span>
images <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
flops<span class="token punctuation">,</span> params <span class="token operator">=</span> profile<span class="token punctuation">(</span>net<span class="token punctuation">,</span> inputs<span class="token operator">=</span><span class="token punctuation">(</span>images<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'FLOPs: </span><span class="token interpolation"><span class="token punctuation">{</span>flops<span class="token punctuation">}</span></span><span class="token string">, Params: </span><span class="token interpolation"><span class="token punctuation">{</span>params<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span></code></pre></div>
<p>发现剪枝效果如下表所示</p>
<table>
<thead>
<tr>
<th>模型类型</th>
<th>FLOPs</th>
<th>Params</th>
</tr>
</thead>
<tbody>
<tr>
<td>初始模型</td>
<td>250408337408.0</td>
<td>3349763.0</td>
</tr>
<tr>
<td>一次剪枝</td>
<td>188382691328.0</td>
<td>2425639.0</td>
</tr>
<tr>
<td>两次剪枝</td>
<td>147422117888.0</td>
<td>1594948.0</td>
</tr>
<tr>
<td>三次剪枝</td>
<td>105292963840.0</td>
<td>921094.0</td>
</tr>
</tbody>
</table>
<p>但是三次剪枝并微调后效果不理想,因此使用两次剪枝的结果移植到rk3588上部署</p>
<h3>参考</h3>
<p>剪枝代码基于: <a href="https://github.com/pachiko/Prune_U-Net">https://github.com/pachiko/Prune_U-Net</a>
剪枝思路基于论文: Pruning Convolutional Neural Networks for Resource Efficient Inference</p>
<h2>部署到rk3588开发板</h2>
<h3>pth模型转化为onnx模型</h3>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F


<span class="token keyword">class</span> <span class="token class-name">DoubleConv</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>DoubleConv<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">Down</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Down<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>mpconv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            DoubleConv<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>mpconv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">Up</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> bilinear<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Up<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> bilinear<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>up <span class="token operator">=</span> nn<span class="token punctuation">.</span>Upsample<span class="token punctuation">(</span>scale_factor<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'bilinear'</span><span class="token punctuation">,</span> align_corners<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>up <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>in_channels <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">,</span> in_channels <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> DoubleConv<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x1<span class="token punctuation">,</span> x2<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x1 <span class="token operator">=</span> self<span class="token punctuation">.</span>up<span class="token punctuation">(</span>x1<span class="token punctuation">)</span>
        diffY <span class="token operator">=</span> x2<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">-</span> x1<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>
        diffX <span class="token operator">=</span> x2<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">-</span> x1<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>

        x1 <span class="token operator">=</span> F<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>x1<span class="token punctuation">,</span> <span class="token punctuation">[</span>diffX <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">,</span> diffX <span class="token operator">-</span> diffX <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">,</span>
                        diffY <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">,</span> diffY <span class="token operator">-</span> diffY <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x2<span class="token punctuation">,</span> x1<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">UNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_channels<span class="token punctuation">,</span> n_classes<span class="token punctuation">,</span> bilinear<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> C_base<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>UNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>n_channels <span class="token operator">=</span> n_channels
        self<span class="token punctuation">.</span>n_classes <span class="token operator">=</span> n_classes
        self<span class="token punctuation">.</span>bilinear <span class="token operator">=</span> bilinear
        self<span class="token punctuation">.</span>C_base <span class="token operator">=</span> C_base

        self<span class="token punctuation">.</span>inc <span class="token operator">=</span> DoubleConv<span class="token punctuation">(</span>n_channels<span class="token punctuation">,</span> C_base<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>down1 <span class="token operator">=</span> Down<span class="token punctuation">(</span>C_base<span class="token punctuation">,</span> C_base <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>down2 <span class="token operator">=</span> Down<span class="token punctuation">(</span>C_base <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> C_base <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>down3 <span class="token operator">=</span> Down<span class="token punctuation">(</span>C_base <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> C_base <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>down4 <span class="token operator">=</span> Down<span class="token punctuation">(</span>C_base <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> C_base <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>up1 <span class="token operator">=</span> Up<span class="token punctuation">(</span>C_base <span class="token operator">*</span> <span class="token number">16</span><span class="token punctuation">,</span> C_base <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> bilinear<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>up2 <span class="token operator">=</span> Up<span class="token punctuation">(</span>C_base <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> C_base <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> bilinear<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>up3 <span class="token operator">=</span> Up<span class="token punctuation">(</span>C_base <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> C_base<span class="token punctuation">,</span> bilinear<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>up4 <span class="token operator">=</span> Up<span class="token punctuation">(</span>C_base <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> C_base<span class="token punctuation">,</span> bilinear<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>outc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>C_base<span class="token punctuation">,</span> n_classes<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x1 <span class="token operator">=</span> self<span class="token punctuation">.</span>inc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x2 <span class="token operator">=</span> self<span class="token punctuation">.</span>down1<span class="token punctuation">(</span>x1<span class="token punctuation">)</span>
        x3 <span class="token operator">=</span> self<span class="token punctuation">.</span>down2<span class="token punctuation">(</span>x2<span class="token punctuation">)</span>
        x4 <span class="token operator">=</span> self<span class="token punctuation">.</span>down3<span class="token punctuation">(</span>x3<span class="token punctuation">)</span>
        x5 <span class="token operator">=</span> self<span class="token punctuation">.</span>down4<span class="token punctuation">(</span>x4<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>up1<span class="token punctuation">(</span>x5<span class="token punctuation">,</span> x4<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>up2<span class="token punctuation">(</span>x<span class="token punctuation">,</span> x3<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>up3<span class="token punctuation">(</span>x<span class="token punctuation">,</span> x2<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>up4<span class="token punctuation">(</span>x<span class="token punctuation">,</span> x1<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>outc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

model <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"model_finetune.pth"</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token string">"cpu"</span><span class="token punctuation">)</span>
net<span class="token operator">=</span>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
example<span class="token operator">=</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span> <span class="token comment">#给定输入</span>
torch<span class="token punctuation">.</span>onnx<span class="token punctuation">.</span>export<span class="token punctuation">(</span>model<span class="token punctuation">,</span><span class="token punctuation">(</span>example<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">'./model_finetune2.onnx'</span><span class="token punctuation">,</span>verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> opset_version<span class="token operator">=</span><span class="token number">17</span><span class="token punctuation">)</span> <span class="token comment">#导出</span></code></pre></div>
<p>注意,虽然我们存储的是完整的模型,但是依旧需要定义原本的UNet模型,并且需要指定map_location以使得模型加载到cpu上</p>
<h3>部署到开发板</h3>
<p>onnx转化为rknn与在开发板上运行的代码已经在上篇文章中写得很详尽了,因而直接放效果图:</p>
<ul>
<li>剪枝后</li>
</ul>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; "
    >
      <a
    class="gatsby-resp-image-link"
    href="/static/5f9382d397c117f6871933e169120932/45662/img.png"
    style="display: block"
    target="_blank"
    rel="noopener"
  >
    <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 58.22784810126582%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAIAAADtbgqsAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB80lEQVR42mP4/+8/Jvr39x8QYZH6j8JlgFB///wDon8Q8u//j++v/vr5DSj+BywINuv/z+9vPr6/DVb/D0UzHADNAZIPX+35+fMzmuCnb49evDsD4iI0A5Vef9yVNLk3dVpzdHdLXG9v4vTWxpYPn96vm7i1Lbq/Pb6/JrS1J2laQ2rb1t2bger//vmL0Hx673lTBldLBg9jRm9zJm9TBhdn2+h3H98XedboMNhaMfuYMvpYM3hpsThMnbMUqP7P7z8Izef3X3ZmCnJlDE3W9wtXCXZkCHK1Snv97l2tb5sVg7cvX0iEeqAXW7gpq9/EaSvAmpFsPrfvkjODvzVL1KyjAXVZ3uYMgW6m6W/eva/xbTVm8IwNip+7zdeVLcyYwWfK1DXoNgM1OzD4OnCGGptk2vFGODD4uOoANX+o9GoxZ3C1V0ixUkx1ZQgyZvCe1LMS3ebz+y45AW1jDnFnDHBjCXFiCPBSS3/z5n21T6sVg5cHS7AbY6AHa5gZg+/MnrUgzb+QbP766dvNM7dvnb1z8/zdm2fv3Lt4f+3CvZ8+fnl+78X1U7duAQXP3bl/6f7hraeP7b8Iiqo/uOL5L4hzcu8FoIkIwX8gwecPX10/exeqBlnzP0hKAiNgivj07vOvn7+QxYGCP7/9/PrpK3IKBQCYpxwjadzJsAAAAABJRU5ErkJggg=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="img.png"
        title=""
        src="/static/5f9382d397c117f6871933e169120932/f058b/img.png"
        srcset="/static/5f9382d397c117f6871933e169120932/c26ae/img.png 158w,
/static/5f9382d397c117f6871933e169120932/6bdcf/img.png 315w,
/static/5f9382d397c117f6871933e169120932/f058b/img.png 630w,
/static/5f9382d397c117f6871933e169120932/40601/img.png 945w,
/static/5f9382d397c117f6871933e169120932/78612/img.png 1260w,
/static/5f9382d397c117f6871933e169120932/45662/img.png 1410w"
        sizes="(max-width: 630px) 100vw, 630px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
  </a>
    </span></p>
<ul>
<li>原模型</li>
</ul>
<p><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; "
    >
      <a
    class="gatsby-resp-image-link"
    href="/static/51d98e1c2e0a837e3e235d4bb5ba18e9/92338/img_1.png"
    style="display: block"
    target="_blank"
    rel="noopener"
  >
    <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 48.734177215189874%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB4klEQVR42mP4/+8/CKGC3z/f/fzxFV303+/v317/+f0PquXffwYg/vf33++fv//8+vPpw6eP7z/8//P/2asDHz8+/f8XaMrv71+/v3rx6tuXnz++v3368iBQ8P+/fzDN//8/uf0sSTcvSTsvQSsnQSs7Sb0gwTvx4ZMHa/o2h0olJevlx2lkJmnmx+qkdTa3/fnxF+SKvzDN9648tGPytWfwMWcMMGcKADFUA24/eDCzbIEeg50jS4AZQ6A9g78pg3t2dsO/nyDN/+Ca71995M4WYs8QWuLpWejj48gQaq4UdfPew3mVS0wY3Lx4wkpDvfxFQi0YAjLS2v7/+oNiM1CzG3OQJUNkxZLY2mp/O4ZgC5mom7cfzq1aYszg7Kmb3L81KkA+1JzBPyux4/9vVGffv/LIhTHImSnIWCTRkjXClSHAUjjy5s2HcyoWGzM4OfPFmPAkOzOGWDH4ZUe0/f+NavPjm0/D5VLCpVOiJJMiZVIipFN8ldLv3Hi0vH2NB2d4lFxalFRSlFyqn2hCZUI/NKj/wqLq75+/Xz9+BaFP3758+PL7x69DW888e/QSKP7l/RegIBD9+Prj+cNXh3ecAYfWP0Q8IyeSf2D22xfvvn7+hpFyfr9+9hbu5v///gMA0H6lmUyhACEAAAAASUVORK5CYII='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="img_1.png"
        title=""
        src="/static/51d98e1c2e0a837e3e235d4bb5ba18e9/f058b/img_1.png"
        srcset="/static/51d98e1c2e0a837e3e235d4bb5ba18e9/c26ae/img_1.png 158w,
/static/51d98e1c2e0a837e3e235d4bb5ba18e9/6bdcf/img_1.png 315w,
/static/51d98e1c2e0a837e3e235d4bb5ba18e9/f058b/img_1.png 630w,
/static/51d98e1c2e0a837e3e235d4bb5ba18e9/40601/img_1.png 945w,
/static/51d98e1c2e0a837e3e235d4bb5ba18e9/78612/img_1.png 1260w,
/static/51d98e1c2e0a837e3e235d4bb5ba18e9/92338/img_1.png 1411w"
        sizes="(max-width: 630px) 100vw, 630px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
  </a>
    </span>
运行速度及参数对比如下图:</p>
<table>
<thead>
<tr>
<th>模型类型</th>
<th>FLOPs</th>
<th>Params</th>
<th>运行速度(ms/张)</th>
</tr>
</thead>
<tbody>
<tr>
<td>初始模型</td>
<td>250408337408.0</td>
<td>3349763.0</td>
<td>120.7</td>
</tr>
<tr>
<td>两次剪枝</td>
<td>147422117888.0</td>
<td>1594948.0</td>
<td>81.6</td>
</tr>
</tbody>
</table>
<p>可以观察到,虽然FLOPs降低了44%左右,但是运行速度只降低了32%左右,这是为什么呢?</p>
<h3>观察与反思</h3>
<p>下表是剪枝后模型各层weight的size</p>
<table>
<thead>
<tr>
<th>层名</th>
<th>size</th>
</tr>
</thead>
<tbody>
<tr>
<td>inc.conv.0.weight</td>
<td>torch.Size([32, 1, 3, 3])</td>
</tr>
<tr>
<td>inc.conv.1.weight</td>
<td>torch.Size([32])</td>
</tr>
<tr>
<td>inc.conv.3.weight</td>
<td>torch.Size([32, 32, 3, 3])</td>
</tr>
<tr>
<td>inc.conv.4.weight</td>
<td>torch.Size([32])</td>
</tr>
<tr>
<td>down1.mpconv.1.conv.0.weight</td>
<td>torch.Size([44, 32, 3, 3])</td>
</tr>
<tr>
<td>down1.mpconv.1.conv.1.weight</td>
<td>torch.Size([44])</td>
</tr>
<tr>
<td>down1.mpconv.1.conv.3.weight</td>
<td>torch.Size([47, 44, 3, 3])</td>
</tr>
<tr>
<td>down1.mpconv.1.conv.4.weight</td>
<td>torch.Size([47])</td>
</tr>
<tr>
<td>down2.mpconv.1.conv.0.weight</td>
<td>torch.Size([88, 47, 3, 3])</td>
</tr>
<tr>
<td>down2.mpconv.1.conv.1.weight</td>
<td>torch.Size([88])</td>
</tr>
<tr>
<td>down2.mpconv.1.conv.3.weight</td>
<td>torch.Size([70, 88, 3, 3])</td>
</tr>
<tr>
<td>down2.mpconv.1.conv.4.weight</td>
<td>torch.Size([70])</td>
</tr>
<tr>
<td>down3.mpconv.1.conv.0.weight</td>
<td>torch.Size([153, 70, 3, 3])</td>
</tr>
<tr>
<td>down3.mpconv.1.conv.1.weight</td>
<td>torch.Size([153])</td>
</tr>
<tr>
<td>down3.mpconv.1.conv.3.weight</td>
<td>torch.Size([139, 153, 3, 3])</td>
</tr>
<tr>
<td>down3.mpconv.1.conv.4.weight</td>
<td>torch.Size([139])</td>
</tr>
<tr>
<td>down4.mpconv.1.conv.0.weight</td>
<td>torch.Size([119, 139, 3, 3])</td>
</tr>
<tr>
<td>down4.mpconv.1.conv.1.weight</td>
<td>torch.Size([119])</td>
</tr>
<tr>
<td>down4.mpconv.1.conv.3.weight</td>
<td>torch.Size([92, 119, 3, 3])</td>
</tr>
<tr>
<td>down4.mpconv.1.conv.4.weight</td>
<td>torch.Size([92])</td>
</tr>
<tr>
<td>up1.conv.conv.0.weight</td>
<td>torch.Size([62, 231, 3, 3])</td>
</tr>
<tr>
<td>up1.conv.conv.1.weight</td>
<td>torch.Size([62])</td>
</tr>
<tr>
<td>up1.conv.conv.3.weight</td>
<td>torch.Size([59, 62, 3, 3])</td>
</tr>
<tr>
<td>up1.conv.conv.4.weight</td>
<td>torch.Size([59])</td>
</tr>
<tr>
<td>up2.conv.conv.0.weight</td>
<td>torch.Size([44, 129, 3, 3])</td>
</tr>
<tr>
<td>up2.conv.conv.1.weight</td>
<td>torch.Size([44])</td>
</tr>
<tr>
<td>up2.conv.conv.3.weight</td>
<td>torch.Size([41, 44, 3, 3])</td>
</tr>
<tr>
<td>up2.conv.conv.4.weight</td>
<td>torch.Size([41])</td>
</tr>
<tr>
<td>up3.conv.conv.0.weight</td>
<td>torch.Size([12, 88, 3, 3])</td>
</tr>
<tr>
<td>up3.conv.conv.1.weight</td>
<td>torch.Size([12])</td>
</tr>
<tr>
<td>up3.conv.conv.3.weight</td>
<td>torch.Size([14, 12, 3, 3])</td>
</tr>
<tr>
<td>up3.conv.conv.4.weight</td>
<td>torch.Size([14])</td>
</tr>
<tr>
<td>up4.conv.conv.0.weight</td>
<td>torch.Size([20, 46, 3, 3])</td>
</tr>
<tr>
<td>up4.conv.conv.1.weight</td>
<td>torch.Size([20])</td>
</tr>
<tr>
<td>up4.conv.conv.3.weight</td>
<td>torch.Size([16, 20, 3, 3])</td>
</tr>
<tr>
<td>up4.conv.conv.4.weight</td>
<td>torch.Size([16])</td>
</tr>
</tbody>
</table>
<p>可以看到,剪枝后各层size的数字呈现杂乱无序的特点,总参数量虽然降低了,但是结构相比之前不适应于硬件架构,导致运行速度降低幅度相对较小</p>
<h3>参考</h3>
<p>南京大学结构化剪枝综述: <a href="https://cs.nju.edu.cn/wujx/paper/Pruning_Survey_MLA21.pdf">https://cs.nju.edu.cn/wujx/paper/Pruning_Survey_MLA21.pdf</a></p></section><hr/><footer><div class="bio"><div data-gatsby-image-wrapper="" style="width:50px;height:50px" class="gatsby-image-wrapper bio-avatar"><div aria-hidden="true" data-placeholder-image="" style="opacity:1;transition:opacity 500ms linear;background-color:#f8f8f8;width:50px;height:50px;position:relative"></div><picture><source type="image/avif" data-srcset="/static/6dacf7b2c4db85249eda1745ffb570ed/d4bf4/profile-pic.avif 50w,/static/6dacf7b2c4db85249eda1745ffb570ed/ee81f/profile-pic.avif 100w" sizes="50px"/><source type="image/webp" data-srcset="/static/6dacf7b2c4db85249eda1745ffb570ed/3faea/profile-pic.webp 50w,/static/6dacf7b2c4db85249eda1745ffb570ed/6a679/profile-pic.webp 100w" sizes="50px"/><img data-gatsby-image-ssr="" layout="fixed" data-main-image="" style="opacity:0" sizes="50px" decoding="async" loading="lazy" data-src="/static/6dacf7b2c4db85249eda1745ffb570ed/e5610/profile-pic.png" data-srcset="/static/6dacf7b2c4db85249eda1745ffb570ed/e5610/profile-pic.png 50w,/static/6dacf7b2c4db85249eda1745ffb570ed/e9b55/profile-pic.png 100w" alt="Profile picture"/></picture><noscript><picture><source type="image/avif" srcSet="/static/6dacf7b2c4db85249eda1745ffb570ed/d4bf4/profile-pic.avif 50w,/static/6dacf7b2c4db85249eda1745ffb570ed/ee81f/profile-pic.avif 100w" sizes="50px"/><source type="image/webp" srcSet="/static/6dacf7b2c4db85249eda1745ffb570ed/3faea/profile-pic.webp 50w,/static/6dacf7b2c4db85249eda1745ffb570ed/6a679/profile-pic.webp 100w" sizes="50px"/><img data-gatsby-image-ssr="" layout="fixed" data-main-image="" style="opacity:0" sizes="50px" decoding="async" loading="lazy" src="/static/6dacf7b2c4db85249eda1745ffb570ed/e5610/profile-pic.png" srcSet="/static/6dacf7b2c4db85249eda1745ffb570ed/e5610/profile-pic.png 50w,/static/6dacf7b2c4db85249eda1745ffb570ed/e9b55/profile-pic.png 100w" alt="Profile picture"/></picture></noscript><script type="module">const t="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;if(t){const t=document.querySelectorAll("img[data-main-image]");for(let e of t){e.dataset.src&&(e.setAttribute("src",e.dataset.src),e.removeAttribute("data-src")),e.dataset.srcset&&(e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset"));const t=e.parentNode.querySelectorAll("source[data-srcset]");for(let e of t)e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset");e.complete&&(e.style.opacity=1,e.parentNode.parentNode.querySelector("[data-placeholder-image]").style.opacity=0)}}</script></div><p>Written by <strong>Kyle Mathews</strong> <!-- -->who lives and works in San Francisco building useful things.<!-- --> <a href="https://twitter.com/kylemathews">You should follow them on Twitter</a></p></div></footer></article><nav class="blog-post-nav"><ul style="display:flex;flex-wrap:wrap;justify-content:space-between;list-style:none;padding:0"><li><a rel="prev" href="/rk3588/">← <!-- -->从医学图像分割pipeline搭建到rk3588板端推理部署</a></li><li></li></ul></nav></main><footer>© <!-- -->2024<!-- -->, Built with<!-- --> <a href="https://www.gatsbyjs.com">Gatsby</a></footer></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/rk3588-prone/";/*]]>*/</script><!-- slice-start id="_gatsby-scripts-1" -->
          <script
            id="gatsby-chunk-mapping"
          >
            window.___chunkMapping="{\"app\":[\"/app-b6908f4eeeae03dc6d46.js\"],\"component---src-pages-404-js\":[\"/component---src-pages-404-js-bf97f439f92c1e7b6282.js\"],\"component---src-pages-index-js\":[\"/component---src-pages-index-js-350e9b4aa85349fee1e3.js\"],\"component---src-pages-using-typescript-tsx\":[\"/component---src-pages-using-typescript-tsx-dc3ca6ac10d2e40c080a.js\"],\"component---src-templates-blog-post-js\":[\"/component---src-templates-blog-post-js-c66e12eb4b10a9ee344e.js\"]}";
          </script>
        <script>window.___webpackCompilationHash="8d6ec6fd2a46dc359fa6";</script><script src="/webpack-runtime-7fdb54d87775eed30ece.js" async></script><script src="/framework-195f9a31e5a4e6cebf51.js" async></script><script src="/app-b6908f4eeeae03dc6d46.js" async></script><!-- slice-end id="_gatsby-scripts-1" --></body></html>